{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T13:46:06.948775Z",
     "start_time": "2019-11-06T13:45:18.891043Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "** DATA PROCESSING COMPLETED **\n",
      "                     pollution  dew  temp   press wnd_dir  wnd_spd  snow  rain\n",
      "date                                                                          \n",
      "2010-01-02 00:00:00      129.0  -16  -4.0  1020.0      SE     1.79     0     0\n",
      "2010-01-02 01:00:00      148.0  -15  -4.0  1020.0      SE     2.68     0     0\n",
      "2010-01-02 02:00:00      159.0  -11  -5.0  1021.0      SE     3.57     0     0\n",
      "2010-01-02 03:00:00      181.0   -7  -5.0  1022.0      SE     5.36     1     0\n",
      "2010-01-02 04:00:00      138.0   -7  -5.0  1022.0      SE     6.25     2     0\n",
      "||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 7 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** NOT REQUIRED DATA COLUMNS DROPPED **\n",
      "||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "** DATA SPLITTING COMPLETED **\n",
      " Training data shape X, y =>  (8760, 1, 8) (8760,)  Testing data shape X, y =>  (35039, 1, 8) (35039,)\n",
      "||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Train on 8760 samples, validate on 35039 samples\n",
      "Epoch 1/50\n",
      " - 2s - loss: 0.2909 - val_loss: 0.1327\n",
      "Epoch 2/50\n",
      " - 1s - loss: 0.0930 - val_loss: 0.0747\n",
      "Epoch 3/50\n",
      " - 1s - loss: 0.0760 - val_loss: 0.0710\n",
      "Epoch 4/50\n",
      " - 1s - loss: 0.0725 - val_loss: 0.0685\n",
      "Epoch 5/50\n",
      " - 1s - loss: 0.0697 - val_loss: 0.0660\n",
      "Epoch 6/50\n",
      " - 1s - loss: 0.0668 - val_loss: 0.0631\n",
      "Epoch 7/50\n",
      " - 1s - loss: 0.0626 - val_loss: 0.0601\n",
      "Epoch 8/50\n",
      " - 1s - loss: 0.0586 - val_loss: 0.0565\n",
      "Epoch 9/50\n",
      " - 1s - loss: 0.0524 - val_loss: 0.0521\n",
      "Epoch 10/50\n",
      " - 1s - loss: 0.0462 - val_loss: 0.0480\n",
      "Epoch 11/50\n",
      " - 1s - loss: 0.0402 - val_loss: 0.0431\n",
      "Epoch 12/50\n",
      " - 1s - loss: 0.0363 - val_loss: 0.0393\n",
      "Epoch 13/50\n",
      " - 1s - loss: 0.0350 - val_loss: 0.0371\n",
      "Epoch 14/50\n",
      " - 1s - loss: 0.0330 - val_loss: 0.0348\n",
      "Epoch 15/50\n",
      " - 1s - loss: 0.0327 - val_loss: 0.0332\n",
      "Epoch 16/50\n",
      " - 1s - loss: 0.0320 - val_loss: 0.0319\n",
      "Epoch 17/50\n",
      " - 1s - loss: 0.0316 - val_loss: 0.0307\n",
      "Epoch 18/50\n",
      " - 1s - loss: 0.0310 - val_loss: 0.0297\n",
      "Epoch 19/50\n",
      " - 1s - loss: 0.0304 - val_loss: 0.0289\n",
      "Epoch 20/50\n",
      " - 1s - loss: 0.0301 - val_loss: 0.0279\n",
      "Epoch 21/50\n",
      " - 1s - loss: 0.0296 - val_loss: 0.0276\n",
      "Epoch 22/50\n",
      " - 1s - loss: 0.0292 - val_loss: 0.0268\n",
      "Epoch 23/50\n",
      " - 1s - loss: 0.0289 - val_loss: 0.0263\n",
      "Epoch 24/50\n",
      " - 1s - loss: 0.0285 - val_loss: 0.0259\n",
      "Epoch 25/50\n",
      " - 1s - loss: 0.0282 - val_loss: 0.0258\n",
      "Epoch 26/50\n",
      " - 1s - loss: 0.0282 - val_loss: 0.0253\n",
      "Epoch 27/50\n",
      " - 1s - loss: 0.0276 - val_loss: 0.0255\n",
      "Epoch 28/50\n",
      " - 1s - loss: 0.0272 - val_loss: 0.0247\n",
      "Epoch 29/50\n",
      " - 1s - loss: 0.0272 - val_loss: 0.0245\n",
      "Epoch 30/50\n",
      " - 1s - loss: 0.0269 - val_loss: 0.0247\n",
      "Epoch 31/50\n",
      " - 1s - loss: 0.0267 - val_loss: 0.0239\n",
      "Epoch 32/50\n",
      " - 1s - loss: 0.0262 - val_loss: 0.0238\n",
      "Epoch 33/50\n",
      " - 1s - loss: 0.0263 - val_loss: 0.0242\n",
      "Epoch 34/50\n",
      " - 1s - loss: 0.0260 - val_loss: 0.0239\n",
      "Epoch 35/50\n",
      " - 1s - loss: 0.0259 - val_loss: 0.0241\n",
      "Epoch 36/50\n",
      " - 1s - loss: 0.0256 - val_loss: 0.0234\n",
      "Epoch 37/50\n",
      " - 1s - loss: 0.0254 - val_loss: 0.0230\n",
      "Epoch 38/50\n",
      " - 1s - loss: 0.0253 - val_loss: 0.0230\n",
      "Epoch 39/50\n",
      " - 1s - loss: 0.0248 - val_loss: 0.0228\n",
      "Epoch 40/50\n",
      " - 1s - loss: 0.0248 - val_loss: 0.0224\n",
      "Epoch 41/50\n",
      " - 1s - loss: 0.0248 - val_loss: 0.0227\n",
      "Epoch 42/50\n",
      " - 1s - loss: 0.0245 - val_loss: 0.0221\n",
      "Epoch 43/50\n",
      " - 1s - loss: 0.0241 - val_loss: 0.0217\n",
      "Epoch 44/50\n",
      " - 1s - loss: 0.0238 - val_loss: 0.0219\n",
      "Epoch 45/50\n",
      " - 1s - loss: 0.0238 - val_loss: 0.0212\n",
      "Epoch 46/50\n",
      " - 1s - loss: 0.0237 - val_loss: 0.0214\n",
      "Epoch 47/50\n",
      " - 1s - loss: 0.0233 - val_loss: 0.0211\n",
      "Epoch 48/50\n",
      " - 1s - loss: 0.0233 - val_loss: 0.0206\n",
      "Epoch 49/50\n",
      " - 1s - loss: 0.0231 - val_loss: 0.0205\n",
      "Epoch 50/50\n",
      " - 1s - loss: 0.0228 - val_loss: 0.0202\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 18.943\n"
     ]
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "from datetime import datetime\n",
    "from math import sqrt\n",
    "from numpy import concatenate\n",
    "from matplotlib import pyplot\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "\n",
    "\n",
    "# load and process data\n",
    "def parse(x):\n",
    "\treturn datetime.strptime(x, '%Y %m %d %H')\n",
    "dataset = read_csv('data.csv',  parse_dates = [['year', 'month', 'day', 'hour']], index_col=0, date_parser=parse)\n",
    "dataset.drop('No', axis=1, inplace=True)\n",
    "dataset.columns = ['pollution', 'dew', 'temp', 'press', 'wnd_dir', 'wnd_spd', 'snow', 'rain']\n",
    "dataset.index.name = 'date'\n",
    "dataset['pollution'].fillna(0, inplace=True)\n",
    "dataset = dataset[24:]\n",
    "print(\"||\"*40)\n",
    "print(\"** DATA PROCESSING COMPLETED **\")\n",
    "print(dataset.head(5))\n",
    "print(\"||\"*40)\n",
    "dataset.to_csv('pollution.csv')\n",
    "\n",
    "# generating dataset plot\n",
    "from pandas import read_csv\n",
    "from matplotlib import pyplot\n",
    "dataset = read_csv('pollution.csv', header=0, index_col=0)\n",
    "values = dataset.values\n",
    "groups = [0, 1, 2, 3, 5, 6, 7]\n",
    "i = 1\n",
    "pyplot.figure()\n",
    "for group in groups:\n",
    "\tpyplot.subplot(len(groups), 1, i)\n",
    "\tpyplot.plot(values[:, group],'k')\n",
    "\tpyplot.title(dataset.columns[group], y=0.5, loc='right')\n",
    "\ti += 1\n",
    "pyplot.show()\n",
    "\n",
    "# Lets normalize all features, and remove the weather variables for the hour to be predicted.\n",
    "import pandas as pd \n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def s_to_super(data, n_in=1, n_out=1, dropnan=True):\n",
    "\tn_vars = 1 if type(data) is list else data.shape[1]\n",
    "\tdf = pd.DataFrame(data)\n",
    "\tcols, names = list(), list()\n",
    "\tfor i in range(n_in, 0, -1):\n",
    "\t\tcols.append(df.shift(i))\n",
    "\t\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\tfor i in range(0, n_out):\n",
    "\t\tcols.append(df.shift(-i))\n",
    "\t\tif i == 0:\n",
    "\t\t\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "\t\telse:\n",
    "\t\t\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\tagg = pd.concat(cols, axis=1)\n",
    "\tagg.columns = names\n",
    "\tif dropnan:\n",
    "\t\tagg.dropna(inplace=True)\n",
    "\treturn agg\n",
    " \n",
    "# load dataset\n",
    "dataset = read_csv('pollution.csv', header=0, index_col=0)\n",
    "values = dataset.values\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "values[:,4] = encoder.fit_transform(values[:,4])\n",
    "values = values.astype('float32')\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled = scaler.fit_transform(values)\n",
    "reframed = s_to_super(scaled, 1, 1)\n",
    "# drop columns we don't want to predict\n",
    "reframed.drop(reframed.columns[[9,10,11,12,13,14,15]], axis=1, inplace=True)\n",
    "print(\"** NOT REQUIRED DATA COLUMNS DROPPED **\")\n",
    "print(\"||\"*40)\n",
    "# split data into training and testing, futher splitting the train and test sets into i/p and o/p variables\n",
    "# reshaped data further into 3D formate expected by LSTMs\n",
    "values = reframed.values\n",
    "n_train_hours = 365 * 24\n",
    "train = values[:n_train_hours, :]\n",
    "test = values[n_train_hours:, :]\n",
    "# split into input and outputs\n",
    "train_X, train_y = train[:, :-1], train[:, -1]\n",
    "test_X, test_y = test[:, :-1], test[:, -1]\n",
    "train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "print(\"** DATA SPLITTING COMPLETED **\")\n",
    "print(\" Training data shape X, y => \",train_X.shape, train_y.shape,\" Testing data shape X, y => \", test_X.shape, test_y.shape)\n",
    "print(\"||\"*40)\n",
    "# defining LSTM with 50 neurons in first hidden layer and 1 neuron in the o/p layer\n",
    "# using the MAE loss function and Adma version of stochastic gradient descent\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense, Dropout\n",
    "model = Sequential()\n",
    "# 50 neurons in first hidden layer\n",
    "model.add(LSTM(50, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(1,kernel_initializer='normal', activation='sigmoid'))\n",
    "model.compile(loss='mae', optimizer='adam')\n",
    "history = model.fit(train_X, train_y, epochs=50, batch_size=72, validation_data=(test_X, test_y), verbose=2, shuffle=False)\n",
    "# tracking history for plots\n",
    "pyplot.plot(history.history['loss'], 'b', label='training history')\n",
    "pyplot.plot(history.history['val_loss'],  'r',label='testing history')\n",
    "pyplot.title(\"Train and Test Loss for the LSTM\")\n",
    "pyplot.legend()\n",
    "pyplot.show()\n",
    "# evaluating model\n",
    "# make a prediction\n",
    "from math import sqrt\n",
    "from numpy import concatenate\n",
    "yhat = model.predict(test_X)\n",
    "test_X = test_X.reshape((test_X.shape[0], test_X.shape[2]))\n",
    "inv_yhat = concatenate((yhat, test_X[:, 1:]), axis=1)\n",
    "inv_yhat = scaler.inverse_transform(inv_yhat)\n",
    "inv_yhat = inv_yhat[:,0]\n",
    "inv_y = scaler.inverse_transform(test_X)\n",
    "inv_y = inv_y[:,0]\n",
    "# calculate RMSE\n",
    "rmse = sqrt(mean_squared_error(inv_y, inv_yhat))\n",
    "print('Test RMSE: %.3f' % rmse)\n"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
